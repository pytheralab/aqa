volumes:
  rtvserving_data:
  sati_data:
  deepseek_data:

services:
  rtvserving:
    image: heronq02/modelhub:rtvserving-hieupth-tritonserver24.12-tensorrt_2412
    volumes:
      - rtvserving_data:/models
    healthcheck:
      test: ["CMD", "bash", "-c", "echo -n '' > /dev/tcp/127.0.0.1/8000"]
      interval: 30s
      timeout: 2m
      retries: 2
    deploy:
      resources:
        reservations:
          devices:
          - driver: nvidia
            device_ids: ['0']
            capabilities: [gpu]
    command: >
      bash -c """tritonserver --model-repository=/models"""

  sat_chunker:
    image: presencesw/sat_chunker:24.12
    ports:
    environment:
      CHUNKER_NAME: "sat_chunker"
    volumes:
      - sati_data:/models
    healthcheck:
      test: ["CMD", "bash", "-c", "echo -n '' > /dev/tcp/127.0.0.1/8000"]
      interval: 30s
      timeout: 2m
      retries: 2
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [gpu]
              device_ids: ["0"]
    command: >
      bash -c "python3 -u choose_mode.py && tritonserver --model-repository=/models"

  deepseek:
    image: presencesw/llamax3-8b-alpaca:24.12
    volumes:
      - ./models:/models
    healthcheck:
      test: ["CMD", "bash", "-c", "echo -n '' > /dev/tcp/127.0.0.1/8000"]
      interval: 60s
      timeout: 2m
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['1']
              capabilities: [gpu]
    command: >
      bash -c """pip install torch 'gguf>=0.10' && tritonserver --model-repository=/models"""
  
  qdrant:
    image: qdrant/qdrant:latest
    volumes:
      - ${PWD}/qdrant_hub:/qdrant/storage
    ports:
      - "1999:6333"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:6333"]
      interval: 10s
      timeout: 5s
      retries: 2

  
  dsclient:
    image: heronq02/dsclient:24.12
    volumes:
      - rtvserving_data:/rtvserving_models
      - sat_chunker_data:/sat_chunker_models
      - ./llm_gradio.py:/llm_gradio.py
      - ./mainapi.py:/mainapi.py
      - ./scripts:/scripts
      - ./src:/src
    env_file:
      - .env
    tty: true
    links:
      - rtvserving:rtvserving
      - sat_chunker:sat_chunker
      - deepseek:deepseek
    depends_on:
      rtvserving:
        condition: service_healthy
      sat_chunker:
        condition: service_healthy
      deepseek:
        condition: service_healthy

    ports:
      - "2222:8000"
      - "2223:7860"
    command: >
      bash -c """bash /scripts/run.sh"""

